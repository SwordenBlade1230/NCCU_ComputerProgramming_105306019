{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 讀入 Fashion MNSIT 數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 欣賞數據集內容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**隨機查看訓練集中的五張圖片和其類別**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pick = np.random.choice(60000, 5, replace=False)\n",
    "plt.figure(figsize=(20,10)) # 調整畫布的大小\n",
    "\n",
    "for i in range(5):\n",
    "    n = pick[i]\n",
    "    ax = plt.subplot(151+i)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(class_names[y_train[n]], fontsize=10)\n",
    "    plt.imshow(x_train[n], cmap='Greys')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 資料整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**將圖片中的像素正規化 range(0, 255) → range(0, 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN的輸入資料需要定義channel的數量，由於該資料集的圖片是灰階的，即一個channel(彩色圖片有三個)，因此必須將X的形狀從 (n, 28, 28) 重塑成  \n",
    "(n, 28, 28, 1)，也就是將channel的數量放在X的第四個維度**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**對y進行獨熱編碼(one-hot encoding)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 打造神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. 基本模型：Keras官網Mnist的cnn範例\n",
    "參考網址：https://keras.io/examples/mnist_cnn/  \n",
    "備註：原本範例的optimizer是用Adadelta，但後來執行程式發生錯誤，因此改用adam。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import keras\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(class_names), activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              #optimizer=keras.optimizers.Adadelta(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 34s 563us/sample - loss: 0.5177 - acc: 0.8185 - val_loss: 0.3351 - val_acc: 0.8796\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 32s 528us/sample - loss: 0.3398 - acc: 0.8785 - val_loss: 0.2852 - val_acc: 0.8970\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 32s 532us/sample - loss: 0.2922 - acc: 0.8937 - val_loss: 0.2632 - val_acc: 0.9019\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 37s 620us/sample - loss: 0.2610 - acc: 0.9053 - val_loss: 0.2387 - val_acc: 0.9126\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 37s 612us/sample - loss: 0.2358 - acc: 0.9141 - val_loss: 0.2259 - val_acc: 0.9169\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 41s 676us/sample - loss: 0.2132 - acc: 0.9213 - val_loss: 0.2223 - val_acc: 0.9198\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 37s 612us/sample - loss: 0.1988 - acc: 0.9271 - val_loss: 0.2135 - val_acc: 0.9213\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 37s 625us/sample - loss: 0.1817 - acc: 0.9334 - val_loss: 0.2062 - val_acc: 0.9248\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 37s 620us/sample - loss: 0.1714 - acc: 0.9365 - val_loss: 0.2134 - val_acc: 0.9239\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 37s 615us/sample - loss: 0.1609 - acc: 0.9399 - val_loss: 0.2218 - val_acc: 0.9212\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 36s 603us/sample - loss: 0.1502 - acc: 0.9434 - val_loss: 0.2111 - val_acc: 0.9310\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 36s 601us/sample - loss: 0.1404 - acc: 0.9469 - val_loss: 0.2170 - val_acc: 0.9275\n",
      "Test loss: 0.21695924699902536\n",
      "Test accuracy: 0.9275\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. 使用Functional API實作的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下為我設計的模型架構，由於透過Functional API可以使訓練的過程分歧之後再合併，因此訓練的過程中，**卷積層我一邊使用relu作為激活函數(branch1)，另一邊則使用sigmoid(branch2)**，再將兩邊的結果合併起來之後做maxpooling。另外，我用**平均最大池化層(average pooling layer)**取代扁平層(flatten layer)，減少模型的訓練參數，讓模型的訓練過程更有效率。\n",
    "\n",
    "備註：模型架構圖的畫法有附在該程式最下方「補充：模型視覺化」的地方\n",
    "\n",
    "<img src=\"model_structure_1.png\" height=\"50%\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "iamge_input (InputLayer)        [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_branch1_conv1 (Conv2D)   (None, 28, 28, 32)   320         iamge_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1_branch2_conv1 (Conv2D)   (None, 28, 28, 32)   320         iamge_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1_branch1_conv2 (Conv2D)   (None, 28, 28, 32)   9248        block1_branch1_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_branch2_conv2 (Conv2D)   (None, 28, 28, 32)   9248        block1_branch2_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_concatenate (Concatenate (None, 28, 28, 64)   0           block1_branch1_conv2[0][0]       \n",
      "                                                                 block1_branch2_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_MaxPooling2D (MaxPooling (None, 14, 14, 64)   0           block1_concatenate[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_branch1_conv1 (Conv2D)   (None, 14, 14, 64)   36928       block1_MaxPooling2D[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_branch2_conv1 (Conv2D)   (None, 14, 14, 64)   36928       block1_MaxPooling2D[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_branch1_conv2 (Conv2D)   (None, 14, 14, 64)   36928       block2_branch1_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_branch2_conv2 (Conv2D)   (None, 14, 14, 64)   36928       block2_branch2_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_concatenate (Concatenate (None, 14, 14, 128)  0           block2_branch1_conv2[0][0]       \n",
      "                                                                 block2_branch2_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2_GlobalAveragePooling2D ( (None, 128)          0           block2_concatenate[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           1290        block2_GlobalAveragePooling2D[0][\n",
      "==================================================================================================\n",
      "Total params: 168,138\n",
      "Trainable params: 168,138\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate, add\n",
    "\n",
    "keras.backend.clear_session() # 清除之前的模型\n",
    "\n",
    "img_input = Input(shape=(28,28,1), name='iamge_input')\n",
    "\n",
    "### convolutional block 1 ###\n",
    "branch1 = Conv2D(32, (3, 3), padding='same', activation='relu', name='block1_branch1_conv1')(img_input)\n",
    "branch1 = Conv2D(32, (3, 3), padding='same', activation='relu', name='block1_branch1_conv2')(branch1)\n",
    "\n",
    "branch2 = Conv2D(32, (3, 3), padding='same', activation='sigmoid', name='block1_branch2_conv1')(img_input)\n",
    "branch2 = Conv2D(32, (3, 3), padding='same', activation='sigmoid', name='block1_branch2_conv2')(branch2)\n",
    "\n",
    "out = concatenate([branch1, branch2], name='block1_concatenate')\n",
    "\n",
    "out = MaxPooling2D(pool_size=(2, 2), name='block1_MaxPooling2D')(out)\n",
    "\n",
    "### convolutional block 2 ###\n",
    "branch1 = Conv2D(64, (3, 3), padding='same', activation='relu', name='block2_branch1_conv1')(out)\n",
    "branch1 = Conv2D(64, (3, 3), padding='same', activation='relu', name='block2_branch1_conv2')(branch1)\n",
    "\n",
    "branch2 = Conv2D(64, (3, 3), padding='same', activation='sigmoid', name='block2_branch2_conv1')(out)\n",
    "branch2 = Conv2D(64, (3, 3), padding='same', activation='sigmoid', name='block2_branch2_conv2')(branch2)\n",
    "\n",
    "out = concatenate([branch1, branch2], name='block2_concatenate')\n",
    "\n",
    "out = GlobalAveragePooling2D(name='block2_GlobalAveragePooling2D')(out)\n",
    "\n",
    "### fully-connected layer as a classfier ###\n",
    "out = Dense(10, activation='softmax')(out)\n",
    "\n",
    "model = Model(img_input, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 79s 1ms/sample - loss: 1.0157 - acc: 0.6253 - val_loss: 0.6613 - val_acc: 0.7644\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.5887 - acc: 0.7873 - val_loss: 0.5617 - val_acc: 0.8045\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.5019 - acc: 0.8201 - val_loss: 0.4979 - val_acc: 0.8256\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.4554 - acc: 0.8383 - val_loss: 0.4497 - val_acc: 0.8419\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.4170 - acc: 0.8532 - val_loss: 0.4204 - val_acc: 0.8513\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.3882 - acc: 0.8620 - val_loss: 0.3970 - val_acc: 0.8627\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.3672 - acc: 0.8703 - val_loss: 0.3786 - val_acc: 0.8683\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.3496 - acc: 0.8752 - val_loss: 0.3722 - val_acc: 0.8716\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.3334 - acc: 0.8805 - val_loss: 0.3581 - val_acc: 0.8718\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.3230 - acc: 0.8846 - val_loss: 0.3737 - val_acc: 0.8678\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.3093 - acc: 0.8899 - val_loss: 0.3306 - val_acc: 0.8838\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.3027 - acc: 0.8912 - val_loss: 0.3337 - val_acc: 0.8843\n",
      "Test loss: 0.33369150480031967\n",
      "Test accuracy: 0.8843\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              #optimizer=keras.optimizers.Adadelta(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據模型的預測結果，目前我的模型架構在測試集的表現上沒有贏過基本模型(88.43% < 92.75%)，至於在模型訓練的過程中「同時使用不同的激活函數分批下去訓練，再將輸出結果合併」是否能夠提升模型的預測能力，由於現在還沒有經過一個嚴謹，而且完整的比較機制，所以暫時沒有辦法做出結論，不過現階段我只是想要是熟悉Functional API的用法，畢竟透過Functional API可以跳脫過去只能以「線性」的方式建模的框架，使模型的架構可以更加多元化，而未來我將會嘗試更多非線性的模型架構。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補充：模型視覺化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過**tensorflow.keras.utils.plot_model**這個method可以將模型的架構畫出來，不過即使我安裝了pydot和graphviz這兩個必要的套件，本地端卻還是一直執行失敗(如下面的輸出結果，明明安裝這兩個套件了，卻還是說我沒安裝...)，似乎還有許多麻煩的議題需要解決，因此之後我是將程式碼放到Colab上運行才能成功畫出模型的架構圖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\kevin\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from pydot) (2.4.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\kevin\\anaconda3\\lib\\site-packages (0.14)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pydot \n",
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
