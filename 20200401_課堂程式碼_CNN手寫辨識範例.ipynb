{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN需要定義channel的數量  \n",
    "灰階圖片只有一個channel(彩色圖片有三個，即RGB)，因此要對維度做修改：(n, 28, 28) --> (n, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train = x_train.reshape(-1, x_train.shape[1], x_train.shape[2], 1) / 255\n",
    "x_train = x_train.reshape(60000, 28, 28, 1) / 255\n",
    "#x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape(10000, 28, 28, 1) / 255\n",
    "#x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[28].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀入必要的函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D # CNN會用到的layer\n",
    "    # Conv2D的2D代表每個「記分板(kernal)」的維度 \n",
    "    # 如果輸入的是2D圖片(無論是灰階或是彩色)都是用Conv2D，輸入的是3D的立體圖片用Conv3D\n",
    "    # Conv2D輸入的是三維數據(width, height, channels)；Conv3D輸入的是四維數據(width, height, depth, channels)\n",
    "from tensorflow.keras.layers import Dense, Flatten # dense = 全連結神經層\n",
    "from tensorflow.keras.optimizers import SGD # 最標準的學習方式：隨機梯度下降法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 打造函數學習機 (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # 打開一個空白的函數學習機"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), padding = 'same', input_shape = (28,28,1), activation = 'relu')) \n",
    "    # padding = 'same': 輸入的維度是多少，無論filter的大小，輸出的維度就是多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出 16 個 28 * 28 矩陣\n",
    "# 輸出的維度應該要是 (28, 28, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出的維度應該要是(14, 14, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出的維度應該要是 (14, 14, 32)\n",
    "# 問題：為何輸出的維度不是(14, 14, 16 * 32)? \n",
    "# --> 因為每個filter的16個channel(輸入有幾個channel就有幾個)會掃過所有和channel對應矩陣後把同一個位置(格子)的結果「全部加起來」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出的維度應該要是(7, 7, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3,3), padding = 'same', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出的維度應該要是(7, 7, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出的維度應該要是(3, 3, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出的維度應該要是3 * 3 * 64 = 576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(54, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 54)                31158     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                550       \n",
      "=================================================================\n",
      "Total params: 55,004\n",
      "Trainable params: 55,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 手動計算每一層有幾個參數，以及神經網路一共有幾個權重要調 ###\n",
    "# 第一個Conv2D層：(3 * 3 + 1(bias)) * 16 = 160\n",
    "# 第二個Conv2D層：(16 * 3 * 3 + 1(bias)) * 32 = 4640\n",
    "# 第三個Conv2D層：(32 * 3 * 3 + 1(bias)) * 64 = 18496\n",
    "# 第一個全連結層：(576 + 1(bias)) * 54 = 31158\n",
    "# 第二個全連結層：(54 + 1(bias)) * 10 = 550\n",
    "# 全部加起來等於55004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer = SGD(lr = 0.087), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 219us/sample - loss: 0.0898 - acc: 0.1079\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0893 - acc: 0.1298\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0883 - acc: 0.3108\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0833 - acc: 0.5149\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.0422 - acc: 0.7469\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0185 - acc: 0.8832\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0135 - acc: 0.9140\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 175us/sample - loss: 0.0110 - acc: 0.9292\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.0096 - acc: 0.9377\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0085 - acc: 0.9463\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0076 - acc: 0.9518\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0069 - acc: 0.9562 - loss: 0.0069 - acc: 0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab1325ea08>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(result[87], y_test[87])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(n):\n",
    "    print('我可愛的 CNN 預測是', result[n])\n",
    "    X = x_test[n].reshape(28,28)\n",
    "    plt.imshow(X, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我可愛的 CNN 預測是 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_predict(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5608b950b34903b40f5147a6599ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='n', max=9999), Button(description='Run Interact', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_predict(n)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(my_predict, n = (0, 9999)) # (要互動的函數, 輸入的範圍)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0063 - acc: 0.9595\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的正確率為 0.9595\n"
     ]
    }
   ],
   "source": [
    "print('測試資料的正確率為', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把我們的model存起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myCNNmodel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
